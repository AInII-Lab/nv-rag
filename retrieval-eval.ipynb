{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8a3c30-ef10-45a0-b0fa-2c90e0cddf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e36ff4-4201-4165-949c-b1cb7f524402",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = SimpleDirectoryReader(input_files=[\"carotis.pdf\", \"schlaganfall.pdf\"]).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fa1a77-f89b-48e5-aee9-731adc52fd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(chunk_size=1024)\n",
    "\n",
    "nodes = splitter.get_nodes_from_documents(docs)\n",
    "\n",
    "print(f\"Created {len(nodes)} nodes from the documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29515c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "carotis_df = pd.read_csv('xxx.csv')\n",
    "stroke_df = pd.read_csv('xxx.csv')\n",
    "\n",
    "carotis_df[\"leitlinie\"] = \"carotis\"\n",
    "stroke_df[\"leitlinie\"] = \"schlaganfall\"\n",
    "\n",
    "carotis_df[\"id\"] = \"c_\" + carotis_df[\"id\"].astype(str)\n",
    "stroke_df[\"id\"] = \"s_\" + stroke_df[\"id\"].astype(str)\n",
    "\n",
    "carotis_df[\"page\"] = \"c_\" + carotis_df[\"page\"].astype(str)\n",
    "stroke_df[\"page\"] = \"s_\" + stroke_df[\"page\"].astype(str)\n",
    "\n",
    "total_eval_df = pd.concat([carotis_df, stroke_df])\n",
    "total_eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4f479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(total_eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfb37b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_retrieval(retriever):\n",
    "    leitlinien_hits = 0\n",
    "    page_hits = 0\n",
    "    total = len(total_eval_df)\n",
    "\n",
    "    for index, row in tqdm(total_eval_df.iterrows(), total=total, desc=\"Processing questions\"):\n",
    "        question = row['example_questions']\n",
    "        \n",
    "        try:\n",
    "            retrieved_nodes = retriever.retrieve(question)\n",
    "        \n",
    "            page_found = any(node.metadata.get('page_label') == row[\"page\"].split(\"_\")[1] for node in retrieved_nodes)\n",
    "            leitlinie_found = any(node.metadata.get('file_name') == f\"{row['leitlinie']}_word.pdf\" for node in retrieved_nodes)\n",
    "        \n",
    "            if leitlinie_found: \n",
    "                leitlinien_hits += 1\n",
    "            \n",
    "            if page_found:\n",
    "                page_hits += 1\n",
    "        except Exception:\n",
    "            print(row)\n",
    "            break\n",
    "\n",
    "    leitlinien_hit_rate = (leitlinien_hits / total) * 100\n",
    "\n",
    "    page_hit_rate = (page_hits / total) * 100\n",
    "\n",
    "    print(f\"Total Page hits: {page_hits}\")\n",
    "    print(f\"Page Hit rate: {page_hit_rate:.2f}%\")\n",
    "    print(f\"Total Leitlinien hits: {leitlinien_hits}\")\n",
    "    print(f\"Leitlinien Hit rate: {leitlinien_hit_rate:.2f}%\")\n",
    "    \n",
    "    return {\n",
    "        \"page_hits\": page_hits,\n",
    "        \"page_hit_rate\": page_hit_rate,\n",
    "        \"leitlinien_hits\": leitlinien_hits,\n",
    "        \"leitlinien_hit_rate\": leitlinien_hit_rate\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8109cf08-c167-474c-b5a0-49bc64ecfee8",
   "metadata": {},
   "source": [
    "## Vanilla BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3611f53-299b-462d-8976-fc8cc2bc2cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retriever = BM25Retriever.from_defaults(\n",
    "    nodes=nodes,\n",
    "    similarity_top_k=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f4e373",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_results = test_retrieval(bm25_retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72af1e2-189b-449d-8e6d-f816d313afc7",
   "metadata": {},
   "source": [
    "## OpenAI Embeddings (text-embedding-3-small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a75d8b-8fb3-43c0-a167-d6f7ffa82ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e825af53-4590-4736-8dc6-55ec5e76af8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6212e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_small_index = VectorStoreIndex(nodes=nodes, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f68aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_retriever = openai_small_index.as_retriever(similarity_top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca21c9de-3dba-4981-b047-fe86eb839c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_small_results = test_retrieval(openai_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff682ab0-c6df-43c7-a17e-2a4df46e3ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_small_index.storage_context.persist(persist_dir=\"data/internal/openai_small_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea9c6b8-dee7-44e8-a847-d51863c3745b",
   "metadata": {},
   "source": [
    "## OpenAI large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523462aa-4f69-46b9-8236-c529075fcedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d27adf5-1f18-44ae-bdc0-542e1536d3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_large_index = VectorStoreIndex(nodes=nodes, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bb9e2b-eb18-4983-9cba-582d6ed71339",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_large_retriever = openai_large_index.as_retriever(similarity_top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e66a6dc-7753-4278-9dcf-2df8b33a97de",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_ai_large_results = test_retrieval(openai_large_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e61f2d-e296-4eb7-a701-acaa6d420668",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_large_index.storage_context.persist(persist_dir=\"data/internal/openai_large_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fe766e-1874-4aa1-8945-64804e18c21e",
   "metadata": {},
   "source": [
    "## Sentence Transformers (sentence-transformers/distiluse-base-multilingual-cased-v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b72aaa2-c381-4838-bb69-ae0ae0d24d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "Settings.embed_model = HuggingFaceEmbedding(\"sentence-transformers/distiluse-base-multilingual-cased-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5866ea-8c38-435d-ad43-6839c622cec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf1_index = VectorStoreIndex(nodes=nodes, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34d21fb-ae9c-46d4-b2ea-b4078826e34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf1_retriever = hf1_index.as_retriever(similarity_top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ff89b1-b336-4e0f-9283-caa6266cba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf1_results = test_retrieval(hf1_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bc0273-af5c-4cb9-9c2f-d6979e2a76de",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf1_index.storage_context.persist('data/internal/hf1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16b898e-90e0-4ec7-9e41-3167506f50bc",
   "metadata": {},
   "source": [
    "## Sentence Transformers (\"BAAI/bge-m3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7f3fa4-c08f-4dd7-9caf-417b02ccba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.embed_model = HuggingFaceEmbedding(\"BAAI/bge-m3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79173195-c091-47cd-a4a0-0afaceaf7b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf2_index = VectorStoreIndex(nodes=nodes, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d45e944-4847-4a8f-a9a9-35cef301aae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf2_retriever = hf2_index.as_retriever(similarity_top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48efa104-99f4-4dea-b85c-2d9e341d4e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2_results = test_retrieval(hf2_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3766f702-bf0e-4ac9-9900-90154ab300d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf2_index.storage_context.persist('data/internal/hf2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6b3882",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_results = pd.DataFrame({\n",
    "    \"BM25\": bm25_results,\n",
    "    \"OpenAI Small\": openai_small_results,\n",
    "    \"OpenAI Large\": open_ai_large_results,\n",
    "    \"HF1\": hf1_results,\n",
    "    \"HF2\": h2_results\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be903acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_results = retrieval_results.transpose()\n",
    "\n",
    "retrieval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c2fe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faf5eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('retrieval_resuts.pickle', 'wb') as handle:\n",
    "    pickle.dump(retrieval_results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f6b463",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('retrieval_resuts.pickle', 'rb') as handle:\n",
    "    retrieval_results = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79ae47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "01d71a3c",
   "metadata": {},
   "source": [
    "## CI from proportions (Wilson Method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2d6b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.proportion import proportion_confint\n",
    "\n",
    "n = 384  \n",
    "\n",
    "ci_lower, ci_upper = proportion_confint(count=(retrieval_results.page_hits).astype(int), \n",
    "                                      nobs=[n] * len(retrieval_results), \n",
    "                                      alpha=0.05,  # 95% confidence interval\n",
    "                                      method='wilson')\n",
    "\n",
    "ci_lower = ci_lower * 100\n",
    "ci_upper = ci_upper * 100\n",
    "\n",
    "ci_upper, ci_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609f0eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_results[\"model\"] = retrieval_results.index.values\n",
    "retrieval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c6c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.container import ErrorbarContainer\n",
    "\n",
    "errors = pd.DataFrame({\n",
    "    'lower': retrieval_results['page_hit_rate'] - ci_lower,\n",
    "    'upper': ci_upper - retrieval_results['page_hit_rate']\n",
    "}).T.values\n",
    "\n",
    "with sns.axes_style(\"white\"):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    ax = sns.barplot(data=retrieval_results, x=\"model\", y=\"page_hit_rate\", capsize=1, \n",
    "                    err_kws={'linewidth': 1}, color=\"darkcyan\")\n",
    "    \n",
    "    ax.errorbar(x=range(len(retrieval_results)), y=retrieval_results['page_hit_rate'],\n",
    "               yerr=errors, fmt='none', color='black', \n",
    "               capsize=2, linewidth=0.8)\n",
    "\n",
    "    for container in ax.containers:\n",
    "        if not isinstance(container, ErrorbarContainer):\n",
    "            ax.bar_label(container, fmt=lambda x: f'{x:.1f}%', padding=15)\n",
    "\n",
    "    ax.set_ylim(0,100)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    ax.set_xlabel(\"Model\")\n",
    "    ax.set_ylabel(\"Page Hit Rate (%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b851a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.stats.proportion import proportions_ztest, proportion_confint\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "total_samples = 384\n",
    "models = {model: retrieval_results.loc[model, \"page_hits\"].astype(int) for model in retrieval_results.model.values}\n",
    "\n",
    "print(\"Model Performance Statistics:\")\n",
    "for model, hits in models.items():\n",
    "    accuracy = (hits / total_samples) * 100\n",
    "    print(f\"{model}: {hits}/{total_samples} ({accuracy:.2f}%)\")\n",
    "\n",
    "print(\"\\nPairwise Statistical Comparisons:\")\n",
    "model_names = list(models.keys())\n",
    "p_values = []\n",
    "comparisons = []\n",
    "z_scores = []\n",
    "\n",
    "for i in range(len(model_names)):\n",
    "    for j in range(i + 1, len(model_names)):\n",
    "        model1, model2 = model_names[i], model_names[j]\n",
    "        count = np.array([models[model1], models[model2]])\n",
    "        nobs = np.array([total_samples, total_samples])\n",
    "        \n",
    "        z_stat, p_value = proportions_ztest(count, nobs)\n",
    "        \n",
    "        comparisons.append(f\"{model1} vs {model2}\")\n",
    "        z_scores.append(z_stat)\n",
    "        p_values.append(p_value)\n",
    "\n",
    "rejected, p_values_corrected, _, _ = multipletests(p_values, alpha=0.05, method='bonferroni')\n",
    "\n",
    "for comp, z, p, p_corr, rej in zip(comparisons, z_scores, p_values, p_values_corrected, rejected):\n",
    "    print(f\"\\n{comp}:\")\n",
    "    print(f\"Z-score: {z:.3f}\")\n",
    "    print(f\"Uncorrected P-value: {p:.4f}\")\n",
    "    print(f\"Bonferroni-corrected P-value: {p_corr:.4f}\")\n",
    "    print(f\"Significant at Î±=0.05 (after Bonferroni correction): {'YES' if rej else 'NO'}\")\n",
    "\n",
    "print(\"\\nConfidence Intervals (95%):\")\n",
    "for model, hits in models.items():\n",
    "    ci_lower, ci_upper = proportion_confint(\n",
    "        count=hits, \n",
    "        nobs=total_samples,\n",
    "        alpha=0.05,  # 95% confidence interval\n",
    "        method='wilson'  # Wilson method is more accurate than normal approximation\n",
    "    )\n",
    "    accuracy = (hits / total_samples) * 100\n",
    "    ci_lower_pct = ci_lower * 100\n",
    "    ci_upper_pct = ci_upper * 100\n",
    "    print(f\"{model}: {accuracy:.2f}% [{ci_lower_pct:.2f}%, {ci_upper_pct:.2f}%]\")\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Hits': models.values(),\n",
    "    'Total': total_samples,\n",
    "    'Accuracy': [hits/total_samples * 100 for hits in models.values()]\n",
    "}, index=models.keys())\n",
    "\n",
    "ci_lower = []\n",
    "ci_upper = []\n",
    "for hits in models.values():\n",
    "    lower, upper = proportion_confint(\n",
    "        count=hits,\n",
    "        nobs=total_samples,\n",
    "        alpha=0.05,\n",
    "        method='wilson'\n",
    "    )\n",
    "    ci_lower.append(lower * 100)\n",
    "    ci_upper.append(upper * 100)\n",
    "\n",
    "results_df['CI_Lower'] = ci_lower\n",
    "results_df['CI_Upper'] = ci_upper\n",
    "\n",
    "print(\"\\nSummary DataFrame:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e537cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Create binary arrays for each model's performance\n",
    "bm25 = np.concatenate([np.ones(315), np.zeros(384 - 315)])\n",
    "openai_small = np.concatenate([np.ones(269), np.zeros(384 - 269)])\n",
    "openai_large = np.concatenate([np.ones(287), np.zeros(384 - 287)])\n",
    "hf1 = np.concatenate([np.ones(131), np.zeros(384 - 131)])\n",
    "hf2 = np.concatenate([np.ones(301), np.zeros(384 - 301)])\n",
    "\n",
    "# Perform Kruskal-Wallis test\n",
    "h_stat, p_value = stats.kruskal(bm25, openai_small, openai_large, hf1, hf2)\n",
    "\n",
    "print(f\"H-statistic: {h_stat}\\nP-value: {p_value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leitlinien_rag_2_0-juoIhNGw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
